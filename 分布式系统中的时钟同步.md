以`make`为例，假如`file.c`修改的时间晚于`file.o`，那么`make`就判断需要编译`file.c`。假如在一个分布式系统上运行这样的软件，就要求整个系统具有统一的时钟或时间戳，而这并非自然达成的。

### 物理时钟

许多电路都有时钟。时钟更接近与计时器，一般是一个周期振荡的石英晶体。每振荡一个周期，便会引起一个寄存器的自减，直到归零则会触发中断，同时寄存器复原。这就是计算器触发定时的方式。

单机系统中所有进程共用一个计数器，即使计数器本身存在误差也不影响时间戳本身的正确性。而多核CPU中，由于每个CPU都带有时钟，每个时钟可能存在微笑偏差，称为 **时钟偏移（clock skew）**。

除了计算机自带的时钟之外，很多情况下计算机会使用外部时钟提供的数据。**协调世界时（Universal Coordinated Time, UTC）** 是国际标准的时间标尺。通过UTC接收器，计算机可以接收UTC短波电台或卫星发送的UTC时间。

### 时钟同步算法

记 $t$ 为UTC时间，$C_p(t)$ 为单机 $p$ 在 $t$ 时的时钟时间，那么时钟同步的目标就是，对于集群中的任意机器 $p$ 、$q$，满足 **精度（precision）** 为 $\pi$。

$$
\forall t, \forall p,q\ :\ \mid C_{p}(t) - C_{q}(t) \mid \le \pi
$$

假设外部具有绝对精准的时钟（一般指UTC），目标也可以表示为将 **准确度（accuracy）** 限制到 $\alpha$

$$
\forall t, \forall p \ :\ \mid C_{p}(t)-t\mid \le\alpha
$$
前者表示内部同步，后者表示外部同步。外部同步的系统保证 $\pi=2\alpha$，但内部精准的系统无法保证外部精准。

对于计算机内部的硬件时钟，由于其不一定完全准确，可能存在 **时钟漂移（clock drift）**。具体来说，我们关注的是 **最大时钟漂移率$\rho$（maximum clock drift rate）**。

记 $F(t)$ 为$t$ 时刻晶振的实际频率，$F$ 是期望频率，则这一规格可以表示为

$$
\forall t\ :\ (1-\rho) \le \cfrac{F(t)}{F}\le (1+\rho)
$$
不难看出

$$
C_{p}(t)=\cfrac{1}{F} \int^{t}_{0}F(t)dt\to \cfrac{dC_{p}(t)}{dt}=\cfrac{F(t)}{t}
$$

故优秀的时钟应保证 $\cfrac{dC_{p}(t)}{dt}$ 在1附近。

### 网络时间协议

网络时间协议（Network Time Protocol，NTP）是一种用于同步时钟的协议。

先从两个服务器开始。若A想要直到与B的时钟偏差量，它需要在时间戳 $T_{1}$ 向B发送请求，记 $T_{2}$ 时到达， B在 $T_{3}$ 向A发送回复，其中记录了 $T_{2}$ 和 $T_{3}$，A在 $T_{4}$ 收到回复，则显然偏移量 $\theta$ 可以计算为：

$$
\theta=T_{3}+\cfrac{(T_{2}-T_{1})+(T_{4}-T_{3})}{2}-T_{4}=(T_{2}-T_{1})+\cfrac{T_{3}-T_{4}}{2}
$$
若 $\theta<0$，代表A的时钟时间小于B，A应该回退时间吗？不可以，这样可能引起本机内容的bug。实际上，A会减小每个时钟中断对应的时间量，直到时钟调整到与B相同

在NTP协议中，同时会记录延迟 $\delta$，共计八次，选取最小的 $\delta$ 作为实际延迟。

$$
\delta=\cfrac{(T_{4}-T_{1})-(T_{3}-T_{2})}{2}
$$

我们更希望调整不精确的机器的时钟。NTP将所有机器根据时钟精度与准度分层，最上层为带有UTC接收器或能接收其他外界时钟的机器。当A请求B的时钟时，只有当A的层数低于B时，才会根据B的时钟调整自己的时钟，同时，其自己的层数变为B的层数减一。

### 伯克利算法

上文的NTP算法中，顶层服务器被动等待其他服务器的询问。而伯克利算法中，顶层的时钟服务器主动轮询所有机器。根据所有机器的响应，时钟服务器重新计算时间，并向其他服务器提供时钟信息。伯克利算法适用于无法与外部通信（无UTC接收器）的集群。

例如，假如时钟服务器本机时间为3:00，机器A与B时间分别为2:50与3:25，则时钟服务器先广播3:00的包，机器A与B回复差值-10与+25，时钟服务器接收后计算得实际时间应设置为3:05，并广播。

### 逻辑时钟

虽然时钟同步自然地可以使用实际时间进行同步，但很多时候我们只关心计算机中事件发生的相对顺序。记录时间发生的顺序的时间戳称为逻辑时钟。

**Lamport逻辑时钟** 是Leslie Lamport提出的用于在分布式系统中标记时间顺序的方法，并不是真正的时钟。它基于两个非常直观的结论，记事件 $a$ 发生在事件 $b$ 之前为 $a \rightarrow b$：
1. 如果 $a$ 与 $b$ 运行在同一进程，$a$ 先于 $b$，则 $a\rightarrow b$
2. 如果 $a$ 是进程发送的消息事件，$b$ 是与之对应另一进程的接收事件，则 $a\rightarrow b$

这一运算符满足偏序关系而不满足全序。如果 $a\rightarrow b$ 且 $b \rightarrow c$，则 $a \rightarrow c$。如果 $x$ 与 $y$ 既不在同一线程又无消息传递，且二者之间无传递关系，则 $x$ 与 $y$ 是并行发生的。

每个进程 $i$ 维护一个计时器 $C_{i}$，通过以下算法维护它的值：
1. 执行事件时，计时器 $C_{i}$ 自增：$C_{i} \leftarrow C_{i}+1$
2. 线程 $P_{i}$ 向 $P_{j}$ 发送消息 $m$ 时，将 $m$ 的时间戳标记为 $ts(m)\leftarrow C_{i}$。
3. $P_{j}$ 接收消息 $m$ 后调整自身的时钟 $C_{j}\leftarrow max\{C_{j}, ts(m)\}$。

为了保证每个事件都有不重复的时间戳，使用进程标识符与原时间戳组成新的元组时间戳。如果两个事件的时间戳相等，例如 $<40, i>$ 与 $<40,j>$，则以进程标识符大小判定事件顺序。

### 向量时钟

由于Lamport时钟并不是一种全序关系，故 $C(a)<C(b)$ 不能推出 $a\rightarrow b$，这一情况主要出现在并发执行的事件中。

向量时钟（Vector Clock）用于解决这一问题。具体来说，每个线程都维护一个向量 $V_{i}$，其中 $V_{i}(j)$ 表示线程 $i$  观测到的 线程 $j$ 的最大时间戳。

具体来说，可以用以下方法维护：
1. 当线程自身产生事件时，$V_{i}(i)$ 自增，其余 $V_{i}(k)$ 不变。
2. 当线程之间发生通信时，发送线程 $i$ 同时将自身的 $V_{i}$ 向量发送给对方。线程 $j$ 利用 $V_{i}$ 更新 $V_{j}$。更新方法如下：
    1. $\forall k\neq j, V_{j}(k)=max\{V_{j}(k), V_{i}(k)\}$
    2. $V_{j}(j)++$

